# NBA Data Engineering Pipeline Project

## ğŸ“š Overview
An end-to-end data engineering pipeline that automates daily NBA game data ingestion from the [balldontlie.io](https://www.balldontlie.io) API, streams data through AWS Kinesis, stores it in S3, and sends daily summary emails with dynamic ESPN recap links.

## ğŸ”— Architecture Overview
- **NBA API Producer**: Python script that fetches daily NBA game data and pushes it to AWS Kinesis.
- **Kinesis Consumer**: Consumes game data from Kinesis shards and writes it into S3 buckets in JSON format.
- **AWS Lambda (nbaDataToS3Notifier)**: Automatically retrieves game data, stores it in S3, and sends an email summary with scores, ESPN recap links, and a JSON download link.

## ğŸš€ Tech Stack
- AWS Kinesis
- AWS S3
- AWS Lambda
- AWS SES
- Python 3.12
- boto3, requests
- Terraform for infrastructure provisioning

## ğŸ“‚ Project Structure
```
â”œâ”€â”€ data_ingestion
â”‚   â”œâ”€â”€ nba_api_producer.py
â”‚   â”œâ”€â”€ kinesis_consumer_to_s3.py
â”œâ”€â”€ lambda_nba_function
â”‚   â”œâ”€â”€ lambda_function.py
â”‚   â”œâ”€â”€ requests/ (dependencies)
â”œâ”€â”€ terraform
â”‚   â”œâ”€â”€ main.tf
â”‚   â”œâ”€â”€ variables.tf
â”‚   â””â”€â”€ outputs.tf
â””â”€â”€ README.md
```

## âš™ï¸ How to Use
### 1. Run Producer
```bash
cd data_ingestion
python nba_api_producer.py
```
### 2. Run Consumer
```bash
python kinesis_consumer_to_s3.py
```
### 3. Deploy Lambda
- Package dependencies and upload as a zip file.
- Set environment variables in AWS Lambda console.
- Trigger manually or schedule with CloudWatch Events.

## âœ… Features
- Automated daily NBA game ingestion.
- Streaming via Kinesis and storage in S3.
- Timestamped JSON storage.
- SES emails with:
  - Game scores
  - Dynamic ESPN recaps
  - JSON data download links.

## ğŸš€ Potential Enhancements
- Add Slack notifications.
- Visualize data in Power BI or Tableau.
- Store historical records in AWS Redshift or RDS.

## ğŸ‘¨ğŸ¾â€ğŸ’» Author
Obinna Okonkwo

## ğŸ“œ License
This project is licensed under the MIT License.
